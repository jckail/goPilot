logging/telemetrylogger_init.go:1: File is not `gci`-ed with --skip-generated -s standard -s default (gci)
package logging

import (
	"context"
	"crypto/tls"
	"fmt"
	"time"

	"go.opentelemetry.io/otel/exporters/otlp/otlpmetric/otlpmetricgrpc"
	"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
	"go.opentelemetry.io/otel/exporters/stdout/stdoutmetric"
	"go.opentelemetry.io/otel/exporters/stdout/stdouttrace"
	sdkmetric "go.opentelemetry.io/otel/sdk/metric"
	"go.opentelemetry.io/otel/sdk/resource"
	sdkTrace "go.opentelemetry.io/otel/sdk/trace"
	"go.uber.org/zap"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
)

func initOtelTracerProvider(config TelemetryConfiguration, otelResource *resource.Resource, logger *zap.Logger) *sdkTrace.TracerProvider {
	traceExporter := getSpanExporter(config.CollectorAddress, logger)

	spanProcessor := sdkTrace.NewBatchSpanProcessor(traceExporter)
	policy := config.SamplingPolicy

	tracerProvider := sdkTrace.NewTracerProvider(
		sdkTrace.WithSampler(policy),
		sdkTrace.WithResource(otelResource),
		sdkTrace.WithSpanProcessor(spanProcessor),
	)

	return tracerProvider
}

// create the opentelemetry span exporter. This is used to send telemetry data to the collector.
// if connection to collector cannot be acquired then stdout exporter is returned.
// if stdout exporter cannot be acquired then noop span exporter is returned.
func getSpanExporter(collectorAddress string, logger *zap.Logger) sdkTrace.SpanExporter {
	timeoutContext, cancel := context.WithTimeout(context.Background(), time.Second*15)
	defer cancel()

	// try to obtain grpc connection
	grpcConnection, connectionError := getCollectorConnection(collectorAddress, timeoutContext)
	if connectionError == nil {
		// initialize grpc span exporter
		traceExporter, exporterErr := otlptracegrpc.New(timeoutContext, otlptracegrpc.WithGRPCConn(grpcConnection))
		if exporterErr == nil {
			return traceExporter
		} else {
			logger.Error(fmt.Errorf("could not start grpc span exporter: %w", exporterErr).Error())
		}
	} else {
		logger.Error(fmt.Errorf("could not start grpc connection: %w", connectionError).Error())
	}

	// if could not create grpc exporter then create standard output exporter
	traceExporter, stdoutTracerError := stdouttrace.New()
	if stdoutTracerError != nil {
		logger.Error(fmt.Errorf("could not start standard output span exporter: %w", stdoutTracerError).Error())

		return otlptracegrpc.NewUnstarted()
	}

	return traceExporter
}

// create a gRPC connection to the collector.
func getCollectorConnection(collectorAddress string, timeoutContext context.Context) (*grpc.ClientConn, error) {
	// #nosec G402
	creds := credentials.NewTLS(&tls.Config{InsecureSkipVerify: false})
	// this does not fail gracefully, if the collector is not available
	grpcConnection, err := grpc.DialContext(timeoutContext,
		collectorAddress,
		grpc.WithTransportCredentials(creds),
		grpc.WithBlock(),
	)
	if err != nil {
		return nil, fmt.Errorf("failed to create gRPC connection to collector: %w", err)
	}

	return grpcConnection, nil
}

// getMetricProvider creates a new metric provider. The metrics provider, wraps the exporter; which will send meter data to the collector or stdout.
func getMetricProvider(config TelemetryConfiguration, otelResource *resource.Resource, logger *zap.Logger) *sdkmetric.MeterProvider {
	exp := getMetricExporter(config, logger)

	return sdkmetric.NewMeterProvider(
		sdkmetric.WithResource(otelResource),
		sdkmetric.WithReader(
			sdkmetric.NewPeriodicReader(
				exp,
				sdkmetric.WithInterval(config.MetricsSamplingInterval),
			),
		))
}

// getMetricExporter creates a new metric exporter. The exporter will send meter data to the collector or stdout.
func getMetricExporter(config TelemetryConfiguration, logger *zap.Logger) sdkmetric.Exporter {
	timeoutContext, cancel := context.WithTimeout(context.Background(), time.Second*15)
	defer cancel()

	connection, err := getCollectorConnection(config.CollectorAddress, timeoutContext)
	if err != nil {
		logger.Error(fmt.Errorf("failed to create gRPC connection to collector. metrics to route to stdout: %w", err).Error())

		// always returns nil error
		stdoutExporter, _ := stdoutmetric.New()

		return stdoutExporter
	}

	exporter, err := otlpmetricgrpc.New(timeoutContext, otlpmetricgrpc.WithGRPCConn(connection))
	if err != nil {
		logger.Error(fmt.Errorf("failed to create GRPC Metric Exporter. metrics to route to stdout: %w", err).Error())

		// always returns nil error
		stdoutExporter, _ := stdoutmetric.New()

		return stdoutExporter
	}

	return exporter
}
logging/metricsmanager.go:1: File is not `gci`-ed with --skip-generated -s standard -s default (gci)
package logging

import (
	"context"
	"fmt"

	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/metric"
	"go.opentelemetry.io/otel/metric/noop"
	"go.uber.org/zap"
)

type metricsManager struct {
	metricProvider metric.MeterProvider
	counters       map[string]metric.Int64Counter
	logger         *zap.Logger
	meter          metric.Meter
}

// metric names.
// these metrics can be increased using logging.TelemetryLogger.
const (
	// counts messages send to kafka.
	msgPublishedCounter = "message_published_counter"

	// counts messages received from kafka.
	msgReceivedCounter = "message_received_counter"

	// counter increased each time the client app try to connect to Databus (kafka or other platform).
	databusConnectionAttemptCounter = "databus_connection_attempt_counter"

	// counter increased each time the client app try to disconnect from Databus (kafka or other platform).
	databusDisconnectionAttemptCounter = "databus_disconnect_attempt_counter"

	// counter increased each time the Databus SDK is initialized by client.
	databusClientInitializationCounter = "databus_client_initialization_counter"
)

func newMetricsManager(config TelemetryConfiguration, meterProvider metric.MeterProvider, logger *zap.Logger) *metricsManager {
	manager := metricsManager{}
	manager.metricProvider = meterProvider
	manager.counters = make(map[string]metric.Int64Counter)
	manager.logger = logger

	attributes := metric.WithInstrumentationAttributes(
		attribute.String("TopicName", config.TopicName))

	manager.meter = meterProvider.Meter(config.InstrumentationScope, attributes)

	manager.initializeCounter(msgPublishedCounter)
	manager.initializeCounter(msgReceivedCounter)
	manager.initializeCounter(databusConnectionAttemptCounter)
	manager.initializeCounter(databusDisconnectionAttemptCounter)
	manager.initializeCounter(databusClientInitializationCounter)

	return &manager
}

func (manager *metricsManager) initializeCounter(name string) {
	counter, err := manager.meter.Int64Counter(name)
	if err != nil {
		manager.logger.Error(fmt.Errorf("could not create counter metric: %w", err).Error())

		counter = noop.Int64Counter{}
	}

	manager.counters[name] = counter
}

func (manager *metricsManager) increaseCounter(ctx context.Context, counterName string, incrBy int64) {
	counter := manager.counters[counterName]
	if counter == nil {
		manager.logger.Error(fmt.Sprintf("Counter %s not initialized!", counterName))
	} else {
		counter.Add(ctx, incrBy)
	}
}
logging/kafkaheadercarrier.go:1: File is not `gci`-ed with --skip-generated -s standard -s default (gci)
package logging

import (
	"github.com/twmb/franz-go/pkg/kgo"
	"go.opentelemetry.io/otel/propagation"
)

// KafkaHeaderCarrier adapts kafka.Header to satisfy the propagation.TextMapCarrier interface.
type KafkaHeaderCarrier []kgo.RecordHeader

// Compile time check that KafkaHeaderCarrier implements the TextMapCarrier.
var _ propagation.TextMapCarrier = &KafkaHeaderCarrier{}

// Get returns the value associated with the passed key.
func (khc *KafkaHeaderCarrier) Get(key string) string {
	for _, h := range *khc {
		if h.Key == key {
			return string(h.Value)
		}
	}

	return ""
}

// Set stores the key-value pair.
func (khc *KafkaHeaderCarrier) Set(key string, value string) {
	for i, h := range *khc {
		if h.Key == key {
			(*khc)[i].Value = []byte(value)

			return
		}
	}

	*khc = append(*khc, kgo.RecordHeader{Key: key, Value: []byte(value)})
}

// Keys lists the keys stored in this carrier.
func (khc *KafkaHeaderCarrier) Keys() []string {
	keys := make([]string, 0, len(*khc))
	for _, h := range *khc {
		keys = append(keys, h.Key)
	}

	return keys
}
logging/loggingerrors.go:1: File is not `gofmt`-ed with `-s` (gofmt)
package logging

import (
	"errors"
)

var (
	ErrServiceNameNotSet          = errors.New("service name not set")
	ErrInstrumentationScopeNotSet = errors.New("instrumentation scope not set")
)
logging/kafkaheadercarrier.go:47: File is not `gofumpt`-ed (gofumpt)

logging/loggingerrors.go:11: File is not `gofumpt`-ed (gofumpt)

logging/metricsmanager.go:78: File is not `gofumpt`-ed (gofumpt)

databus_errors.go:1: File is not `gofmt`-ed with `-s` (gofmt)
package databus

import "fmt"

// ErrNotYetImplemented is returned when a function is not yet implemented.
// This is a temporary error and will be removed for production.
var ErrNotYetImplemented = fmt.Errorf("not yet implemented")

// ErrInvalidDatabusType is returned when the data bus type is invalid.
var ErrInvalidDatabusType = fmt.Errorf("invalid data bus type")

// ErrInvalidSubscriber is returned when the subscriber is not initialized.
var ErrInvalidSubscriber = fmt.Errorf("unitialized subscriber")

// ErrInvalidPublisher is returned when the publisher is not initialized.
var ErrInvalidPublisher = fmt.Errorf("unitialized publisher")

// ErrInvalidSerde is returned when the serde is not initialized.
var ErrInvalidSerde = fmt.Errorf("unitialized serde")

// ErrNonExistentTopic is returned when the topic for the configured schema does not exist.
var ErrNonExistentTopic = fmt.Errorf("topic does not exist")

// ErrUninitializedClient is returned when the client is not initialized.
var ErrUninitializedClient = fmt.Errorf("uninitialized client")

// ErrInvalidOverride is returned when the overrides are invalid for the environment.
var ErrInvalidOverride = fmt.Errorf("invalid client override")

// ErrFailedToDeserializeMessage is returned when a message cannot be deserialized from the data bus.
var ErrFailedToDeserializeMessage = fmt.Errorf("failed to deserialize message")

// ErrNoVersionHeader is returned when the read message does not have a version header.
var ErrNoVersionHeader = fmt.Errorf("no version header")
export_test.go:1: File is not `gofmt`-ed with `-s` (gofmt)
package databus

var (
	InitClientOptions = initClientOptions
	CreateClient      = createClient
)
logging/kafkaheadercarrier_test.go:29:82: directive `//nolint:gosec // length was checked above` is unused for linter "gosec" (nolintlint)
	assert.Equal(t, kgo.RecordHeader{Key: "foo", Value: []byte("bar")}, carrier[0]) //nolint:gosec // length was checked above
	                                                                                ^
logging/kafkaheadercarrier_test.go:30:82: directive `//nolint:gosec // length was checked above` is unused for linter "gosec" (nolintlint)
	assert.Equal(t, kgo.RecordHeader{Key: "baz", Value: []byte("qux")}, carrier[1]) //nolint:gosec // length was checked above
	                                                                                ^
